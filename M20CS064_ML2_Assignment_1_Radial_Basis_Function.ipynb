{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M20CS064 ML2 Assignment 1 Radial Basis Function.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDH88qBLK6Wj"
      },
      "source": [
        "#Problem Statement\n",
        "\n",
        "Q3. Use any toolbox in python and implement RBF NNet to solve one of the problems/databases (of your choice from the UCI ML database Repo). Analyze your results with respect to varying learning rate and epochs. You are not allowed to use someone's code available online. UCI databases: https://archive.ics.uci.edu/ml/datasets.php\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1XhEweSC8hI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "11084378-919c-464a-8bda-808c882b0c67"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-26bb9c3f4f61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPvN7WHZPcbf"
      },
      "source": [
        "train_mnist = datasets.MNIST(root='https://archive.ics.uci.edu/ml/machine-learning-databases/mnist-mld',\n",
        "                          train=True,\n",
        "                          transform=torchvision.transforms.ToTensor(),\n",
        "                          download=True)    #load train data\n",
        "\n",
        "test_mnist = datasets.MNIST(root='https://archive.ics.uci.edu/ml/machine-learning-databases/mnist-mld',\n",
        "                         train=False,\n",
        "                         transform=torchvision.transforms.ToTensor(),\n",
        "                         download=True)     #load test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gePldk86A3A1"
      },
      "source": [
        "print(train_mnist.train_data.size())  # (60000, 28, 28)\r\n",
        "print(train_mnist.train_labels.size())  # (60000)\r\n",
        "print(test_mnist.test_data.size())  #(10000, 28, 28)\r\n",
        "print(test_mnist.test_labels.size())    #(10000)\r\n",
        "\r\n",
        "plt.imshow(train_mnist.train_data[0,:,:].numpy(), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgzy3LuNCwi7"
      },
      "source": [
        "batch_size = 2000\r\n",
        "data_loader = torch.utils.data.DataLoader(dataset=train_mnist,\r\n",
        "                                          batch_size=batch_size,\r\n",
        "                                          shuffle=True,\r\n",
        "                                          num_workers=1)    #iterable on train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl7bZ_F2EhFB"
      },
      "source": [
        "images_batch, labels_batch = next(iter(data_loader))    \r\n",
        "\r\n",
        "print(images_batch.size())\r\n",
        "print(labels_batch.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3pIqKM0QgWE"
      },
      "source": [
        "device = device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    #assign gpu device name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EAvQQ1BFt3t"
      },
      "source": [
        "class Rbf(nn.Module):\r\n",
        "    def __init__(self, centers, num_classes=10):\r\n",
        "        super(Rbf, self).__init__()\r\n",
        "        self.centers = nn.Parameter(centers)        #means of Gaussian\r\n",
        "        self.num_centers = centers.size(0)\r\n",
        "        self.num_classes = num_classes\r\n",
        "    \r\n",
        "        self.linear = torch.nn.Linear(self.num_centers, self.num_classes, bias=True)    #Linear layer\r\n",
        "        self.sigmas = nn.Parameter(torch.ones(1,self.num_centers)/4)    #sigmas of Gaussian\r\n",
        "\r\n",
        "    def radial_function(self, batches):\r\n",
        "        n_input = batches.size(0) # number of inputs\r\n",
        "        Mu = self.centers.view(self.num_centers,-1).repeat(n_input,1,1) #reshape Mu \r\n",
        "        X = batches.view(n_input,-1).unsqueeze(1).repeat(1,self.num_centers,1)  #reshape X\r\n",
        "        Phi = torch.exp(-self.sigmas.mul((X-Mu).pow(2).sum(2,keepdim=False)))   #using gaussian radial function as discussed in lecture\r\n",
        "        return Phi\r\n",
        "    \r\n",
        "    def forward(self, batches): #forward pass\r\n",
        "        Phi = self.radial_function(batches) #radial layer\r\n",
        "        fx = self.linear(Phi)   #linear layer\r\n",
        "        return fx\r\n",
        "\r\n",
        "centers = images_batch.view(-1, 28*28)  #initialize centers to some examples\r\n",
        "#centers = torch.rand(1000,28*28)\r\n",
        "model = Rbf(centers.to(device), num_classes=10) #model initialized\r\n",
        "model.to(device)    #send to GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "882nbT4OSudG"
      },
      "source": [
        "#initializations for benchmarking\r\n",
        "train_loss = [None]*20  \r\n",
        "test_performance = [None]*20\r\n",
        "lr_list = []\r\n",
        "\r\n",
        "\r\n",
        "for itr in range(50, 1001, 50):\r\n",
        "    \r\n",
        "    learning_rate = 0.00001 * itr\r\n",
        "    lr_list.append(learning_rate)\r\n",
        "    training_epochs = 2\r\n",
        "\r\n",
        "    #loss function\r\n",
        "    loss_function = torch.nn.CrossEntropyLoss()     #using CrossEntropyLoss   \r\n",
        "    \r\n",
        "    # Adam Optimizer\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  #using Adam Optimizer\r\n",
        "    \r\n",
        "\r\n",
        "    batch_size = 150\r\n",
        "    # dataset loader\r\n",
        "    data_loader = torch.utils.data.DataLoader(dataset=train_mnist,\r\n",
        "                                            batch_size=batch_size,\r\n",
        "                                            shuffle=True,\r\n",
        "                                            num_workers=4)  #iterator on training data\r\n",
        "    images_batch, labels_batch = next(iter(data_loader))\r\n",
        "\r\n",
        "    model(images_batch.requires_grad_(False).to(device))    #drop gradient requirements \r\n",
        "\r\n",
        "    # Model Training\r\n",
        "    for epoch in range(training_epochs):\r\n",
        "        avg_loss = 0\r\n",
        "        num_batches = len(train_mnist) // batch_size    \r\n",
        "\r\n",
        "        for i, (images_batch, labels_batch) in enumerate(data_loader):        \r\n",
        "            X = images_batch.view(-1, 28 * 28).to(device)\r\n",
        "            Y = labels_batch.to(device)        \r\n",
        "            optimizer.zero_grad()             #Nullify gradients\r\n",
        "            Y_prediction = model(X)           # Forward Pass\r\n",
        "            loss = loss_function(Y_prediction, Y) #compute cost\r\n",
        "            loss.backward()                   #compute gradient\r\n",
        "            optimizer.step()                  #gradient update\r\n",
        "\r\n",
        "            avg_loss += loss / num_batches  #average loss per epoch\r\n",
        "\r\n",
        "        print(f\"Iteration Number: {itr//50} Epoch: {epoch+1} training loss = {avg_loss.data}\")\r\n",
        "        train_loss[itr//50 - 1] = avg_loss\r\n",
        "\r\n",
        "    print('Training over!')\r\n",
        "    # Test the Model\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for images, labels in test_mnist:\r\n",
        "        images = images.view(-1, 28*28).to(device)\r\n",
        "        outputs = model(images) #check on test data\r\n",
        "        _, predicted = torch.max(outputs.data, 1)   #select max value from predictions\r\n",
        "        total += 1\r\n",
        "        correct += (predicted == labels).sum()\r\n",
        "    accuracy = 100 * correct / total\r\n",
        "    print(f'Accuracy of the network on the 10000 test images for learning rate {learning_rate}: {accuracy:.2f}%')\r\n",
        "    test_performance[itr//50 - 1] = accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_hd4-khrAPX"
      },
      "source": [
        "f, a = plt.subplots(1, 2, sharex=True, figsize = (10, 8))\r\n",
        "# plt.xticks()\r\n",
        "a[0].bar(lr_list, [x.data.item() for x in train_loss], width = 0.0003, label='Train Loss', color = 'orange')\r\n",
        "a[1].bar(lr_list, [x.data.item() for x in test_performance], width = 0.0003, label='Test Accuracies')\r\n",
        "a[0].set_xticklabels(lr_list, rotation = 'vertical')\r\n",
        "a[0].set_xticks(lr_list)\r\n",
        "a[1].set_xticklabels(lr_list, rotation = 'vertical')\r\n",
        "\r\n",
        "a[0].title.set_text('Train loss vs Learning rate')\r\n",
        "a[1].title.set_text('Test accuracy vs Learning rate')\r\n",
        "a[0].legend(loc='upper center')\r\n",
        "a[1].legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHevidNJWh3n"
      },
      "source": [
        "train_loss = [None]*10\r\n",
        "test_performance = [None]*10\r\n",
        "epoch_list = []\r\n",
        "for training_epochs in range(5, 50, 5):\r\n",
        "    epoch_list.append(training_epochs)\r\n",
        "    learning_rate = 0.0075\r\n",
        "\r\n",
        "    # Adam Optimizer\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "    batch_size = 150\r\n",
        "    # dataset loader\r\n",
        "    data_loader = torch.utils.data.DataLoader(dataset=train_mnist,\r\n",
        "                                            batch_size=batch_size,\r\n",
        "                                            shuffle=True,\r\n",
        "                                            num_workers=4)\r\n",
        "    images_batch, labels_batch = next(iter(data_loader))\r\n",
        "\r\n",
        "    model(images_batch.requires_grad_(False).to(device))\r\n",
        "\r\n",
        "    # Model Training\r\n",
        "    for epoch in range(training_epochs):\r\n",
        "        avg_loss = 0\r\n",
        "        num_batches = len(train_mnist) // batch_size\r\n",
        "\r\n",
        "        for i, (images_batch, labels_batch) in enumerate(data_loader):        \r\n",
        "            X = images_batch.view(-1, 28 * 28).to(device)\r\n",
        "            Y = labels_batch.to(device)        \r\n",
        "            optimizer.zero_grad()             \r\n",
        "            Y_prediction = model(X)           # Forward Pass\r\n",
        "            loss = loss_function(Y_prediction, Y) #compute cost\r\n",
        "            loss.backward()                   #compute gradient\r\n",
        "            optimizer.step()                  #gradient update\r\n",
        "\r\n",
        "            avg_loss += loss / num_batches\r\n",
        "\r\n",
        "        print(f\"Iteration Number: {training_epochs // 5} Epoch: {epoch+1} training loss = {avg_loss.data:.4f}\")\r\n",
        "        train_loss[training_epochs//5 - 1] = avg_loss\r\n",
        "\r\n",
        "    print('Training over!')\r\n",
        "    # Test the Model\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for images, labels in test_mnist:\r\n",
        "        images = images.view(-1, 28*28).to(device)\r\n",
        "        outputs = model(images)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        total += 1\r\n",
        "        correct += (predicted == labels).sum()\r\n",
        "    accuracy = 100 * correct / total\r\n",
        "    print(f'Accuracy of the network on the 10000 test images for learning rate {learning_rate}: {accuracy:.2f}%')\r\n",
        "    test_performance[training_epochs//5 - 1] = accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41CENo-MG4dJ"
      },
      "source": [
        "f, a = plt.subplots(1, 2, sharex=True, figsize = (10, 10))\r\n",
        "bar0 = [x.data.item() for x in train_loss[:9]]\r\n",
        "bar1 = [x.data.item() for x in test_performance[:9]]\r\n",
        "a[0].bar(epoch_list, bar0, label='Train Loss', color = 'orange')\r\n",
        "a[1].bar(epoch_list, bar1, label='Test Accuracies')\r\n",
        "# a[0][i].set_xticks(())\r\n",
        "# a[0][i].set_yticks(())\r\n",
        "#finding c corresponding to max value\r\n",
        "ymax0 = max(bar0)\r\n",
        "xpos0 = bar0.index(ymax0)\r\n",
        "xmax0 = epoch_list[xpos0]\r\n",
        "\r\n",
        "ymax1 = max(bar1)\r\n",
        "xpos1 = bar1.index(ymax1)\r\n",
        "xmax1 = epoch_list[xpos1]\r\n",
        "\r\n",
        "a[0].title.set_text('Average train loss vs Number of Epochs')\r\n",
        "plt.annotate(f'max (epoch = {epoch_list[xpos1]})', (xmax1,ymax1), (xmax1+3, ymax1+3), arrowprops=dict(facecolor='orange'), fontvariant='small-caps', fontweight='bold', color='orange')\r\n",
        "a[1].title.set_text('Test accuracy vs Number of Epochs')\r\n",
        "plt.xticks(epoch_list)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}